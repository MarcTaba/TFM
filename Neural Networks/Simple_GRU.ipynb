{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUWr8gKNQLt3"
   },
   "source": [
    "# Simplest RNN using GRU units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import platform\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MUJRpzkMQMNq"
   },
   "outputs": [],
   "source": [
    "#read all the data:\n",
    "items = pd.read_csv(\"item_features.csv\")\n",
    "purchase =  pd.read_csv(\"train_purchases.csv\")\n",
    "sessions =  pd.read_csv(\"train_sessions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Z-5Yes-QOgv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "purchase['date'] = pd.to_datetime(purchase['date'])\n",
    "sessions['date'] = pd.to_datetime(sessions['date'])\n",
    "max_day = purchase['date'].max() #max date 31/05/2021 \n",
    "min_day = max_day -datetime.timedelta(31)\n",
    "cond = purchase['date'] >= min_day\n",
    "new_purchases = purchase[cond]\n",
    "top_seller = new_purchases['item_id'].value_counts()[0:100].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbaEJpPMQgvq"
   },
   "outputs": [],
   "source": [
    "max_day = sessions['date'].max() #max date 31/05/2021 \n",
    "testing_date = max_day -datetime.timedelta(31)\n",
    "cond_test = sessions['date'] >= testing_date\n",
    "cond_train = sessions['date'] < testing_date\n",
    "cond_test_purchase = purchase.date >= testing_date\n",
    "cond_train_purchase = purchase.date < testing_date\n",
    "sessions_train = sessions[cond_train]\n",
    "sessions_test = sessions[cond_test]\n",
    "purchase_train = purchase[cond_train_purchase]\n",
    "purchase_test = purchase[cond_test_purchase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yn-tIE4QjQk"
   },
   "outputs": [],
   "source": [
    "def sessions_list(sessions,purchase):\n",
    "    antique_session = sessions.iat[0,0]\n",
    "    list_sessions = []\n",
    "    actual_session = []\n",
    "    purchase_session = 0\n",
    "    for i in tqdm(range(len(sessions))):\n",
    "        new_session = sessions.iat[i,0]\n",
    "        item = sessions.iat[i,1]\n",
    "        if(new_session != antique_session):\n",
    "            actual_session.append(purchase.iat[purchase_session,1])\n",
    "            purchase_session += 1\n",
    "            list_sessions.append(actual_session)\n",
    "            actual_session = []\n",
    "            antique_session = new_session\n",
    "        actual_session.append(item)\n",
    "    list_sessions.append(actual_session)\n",
    "    return list_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huvCSDNFQk_L",
    "outputId": "56905552-547a-4b4a-f8ae-d573d32bfc2d"
   },
   "outputs": [],
   "source": [
    "session_item = sessions_list(sessions,purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fg1LxXAiQl92",
    "outputId": "7a398c9d-9ec6-4999-f426-a104d648c226"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [00:04, 244443.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def training_sequences(session_item2):\n",
    "    train_sequence = np.zeros((len(session_item2),6))\n",
    "    trobat = False\n",
    "    for i,x in tqdm(enumerate(session_item2)):\n",
    "        length = len(x)\n",
    "        llista = x.copy()\n",
    "        if(length-1 < 5):\n",
    "            for j in range(5-length+1):\n",
    "                llista.insert(0,0)\n",
    "        if(length-1 > 5):\n",
    "            for j in range(length-6):\n",
    "                llista.pop(0)\n",
    "        llista.pop(-1)                                    \n",
    "        train_sequence[i][0] = llista[0]\n",
    "        train_sequence[i][1] = llista[1]\n",
    "        train_sequence[i][2] = llista[2]\n",
    "        train_sequence[i][3] = llista[3]\n",
    "        train_sequence[i][4] = llista[4]\n",
    "        train_sequence[i][5] = x[len(x)-1]\n",
    "    return train_sequence\n",
    "\n",
    "sequence_training = training_sequences(session_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7xlbltcCQppz"
   },
   "outputs": [],
   "source": [
    "X = np.array(sequence_training)[:,:5] #sequence to predict from\n",
    "y = np.array(sequence_training)[:,5:] #next item in the sequence\n",
    "X = X.astype(int)\n",
    "y = y.astype(int)\n",
    "training = np.array(sequence_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz-kLc56QzyP"
   },
   "source": [
    "# Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "zJniifs2Qsoy"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, RNN, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQcv2QizQxm-",
    "outputId": "9bfd5e56-40d2-4201-e08b-39724697f10d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23692"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_items = len(items.item_id.unique())\n",
    "number_items += 1\n",
    "number_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "L7bxZNRLQyuO"
   },
   "outputs": [],
   "source": [
    "item_index = {}\n",
    "index_item = {}\n",
    "item_index[0] = 0\n",
    "index_item[0] = 0\n",
    "for i,x in enumerate(items.item_id.unique()):\n",
    "    index_item[i+1] = x\n",
    "    item_index[x] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "0HTXjD8cQ37R"
   },
   "outputs": [],
   "source": [
    "def training_dataset(X2,y2):\n",
    "    #first X.\n",
    "    X_training = np.zeros((X2.shape[0],X2.shape[1]))\n",
    "    y_training = np.zeros(y2.shape[0])\n",
    "    \n",
    "    for i in range(X2.shape[0]):\n",
    "        for j in range(X2.shape[1]):\n",
    "            X_training[i,j] = item_index[X2[i,j]]\n",
    "    \n",
    "    for i in range(y2.shape[0]):\n",
    "        y_training[i] = item_index[y2[i][0]]\n",
    "            \n",
    "    return X_training, y_training\n",
    "X_training, y_training = training_dataset(X,y)  \n",
    "X_training = X_training.astype(int)\n",
    "y_training = y_training.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "i32c-lTKQ5lS"
   },
   "outputs": [],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "\n",
    "    model.add(GRU(100))\n",
    "\n",
    "    model.add(Dropout(0.1))\n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vSaLv2iQQ8EZ"
   },
   "outputs": [],
   "source": [
    "#let's define a sparse categorical crossentropy to start!\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BOEfirzPwiIf"
   },
   "outputs": [],
   "source": [
    "#let's define a sparse categorical crossentropy to start!\n",
    "def loss2(labels, logits):\n",
    "  print(labels)\n",
    "  labels = int(labels)\n",
    "  index = item_index[labels]\n",
    "  return 1\n",
    "  logits2 = np.array(logits)\n",
    "  return 1\n",
    "  res = list(sorted(enumerate(test_list)))[-100:]\n",
    "  for i in range(100):\n",
    "    if(index == res[i][0]): return 1\n",
    "  return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kunRhnE9-p98"
   },
   "source": [
    "**Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "SnfBlhr8-rJ3"
   },
   "outputs": [],
   "source": [
    "#let's define a sparse categorical crossentropy to start!\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "def top_5(y_true, y_pred):\n",
    "    return  tf.keras.metrics.sparse_top_k_categorical_accuracy(\n",
    "    y_true, y_pred, k=5\n",
    ")\n",
    "def top_50(y_true, y_pred):\n",
    "    return  tf.keras.metrics.sparse_top_k_categorical_accuracy(\n",
    "    y_true, y_pred, k=50\n",
    ")\n",
    "def top_100(y_true, y_pred):\n",
    "    return  tf.keras.metrics.sparse_top_k_categorical_accuracy(\n",
    "    y_true, y_pred, k=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUSVKOVq-1rt"
   },
   "source": [
    "**Model Compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kE0LVrtRc9q",
    "outputId": "2ddb3463-fde2-446c-cc71-ab475d936b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.25.77.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.25.77.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.25.77.202:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.25.77.202:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bUUBRSkwT_i",
    "outputId": "4fdda004-a677-4216-b260-da796dc72509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 4119 calls to <function Model.make_train_function.<locals>.train_function at 0x7f428f1690e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 4119 calls to <function Model.make_train_function.<locals>.train_function at 0x7f428f1690e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7735/7735 [==============================] - 60s 8ms/step - loss: 8.4281 - acc: 0.0134 - top_5: 0.0370 - top_100: 0.1896 - val_loss: 7.7288 - val_acc: 0.0278 - val_top_5: 0.0685 - val_top_100: 0.2856\n",
      "Epoch 2/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 7.4095 - acc: 0.0354 - top_5: 0.0934 - top_100: 0.3399 - val_loss: 7.1461 - val_acc: 0.0467 - val_top_5: 0.1184 - val_top_100: 0.3945\n",
      "Epoch 3/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.9898 - acc: 0.0511 - top_5: 0.1304 - top_100: 0.4179 - val_loss: 6.9253 - val_acc: 0.0606 - val_top_5: 0.1476 - val_top_100: 0.4342\n",
      "Epoch 4/100\n",
      "7735/7735 [==============================] - 45s 6ms/step - loss: 6.7516 - acc: 0.0614 - top_5: 0.1532 - top_100: 0.4609 - val_loss: 6.7900 - val_acc: 0.0710 - val_top_5: 0.1639 - val_top_100: 0.4613\n",
      "Epoch 5/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.5947 - acc: 0.0689 - top_5: 0.1679 - top_100: 0.4879 - val_loss: 6.7265 - val_acc: 0.0717 - val_top_5: 0.1706 - val_top_100: 0.4731\n",
      "Epoch 6/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.4800 - acc: 0.0739 - top_5: 0.1784 - top_100: 0.5066 - val_loss: 6.7032 - val_acc: 0.0736 - val_top_5: 0.1785 - val_top_100: 0.4798\n",
      "Epoch 7/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.3912 - acc: 0.0780 - top_5: 0.1866 - top_100: 0.5214 - val_loss: 6.6797 - val_acc: 0.0767 - val_top_5: 0.1803 - val_top_100: 0.4860\n",
      "Epoch 8/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.3191 - acc: 0.0811 - top_5: 0.1933 - top_100: 0.5327 - val_loss: 6.6951 - val_acc: 0.0760 - val_top_5: 0.1834 - val_top_100: 0.4826\n",
      "Epoch 9/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.2592 - acc: 0.0840 - top_5: 0.1991 - top_100: 0.5424 - val_loss: 6.6967 - val_acc: 0.0777 - val_top_5: 0.1850 - val_top_100: 0.4850\n",
      "Epoch 10/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.2081 - acc: 0.0865 - top_5: 0.2038 - top_100: 0.5503 - val_loss: 6.6970 - val_acc: 0.0777 - val_top_5: 0.1833 - val_top_100: 0.4862\n",
      "Epoch 11/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.1623 - acc: 0.0886 - top_5: 0.2081 - top_100: 0.5575 - val_loss: 6.7021 - val_acc: 0.0795 - val_top_5: 0.1862 - val_top_100: 0.4862\n",
      "Epoch 12/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.1227 - acc: 0.0912 - top_5: 0.2116 - top_100: 0.5640 - val_loss: 6.7080 - val_acc: 0.0818 - val_top_5: 0.1875 - val_top_100: 0.4851\n",
      "Epoch 13/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 6.0876 - acc: 0.0926 - top_5: 0.2152 - top_100: 0.5691 - val_loss: 6.7226 - val_acc: 0.0790 - val_top_5: 0.1878 - val_top_100: 0.4858\n",
      "Epoch 14/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 6.0573 - acc: 0.0942 - top_5: 0.2190 - top_100: 0.5742 - val_loss: 6.7301 - val_acc: 0.0815 - val_top_5: 0.1877 - val_top_100: 0.4806\n",
      "Epoch 15/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 6.0286 - acc: 0.0959 - top_5: 0.2215 - top_100: 0.5788 - val_loss: 6.7484 - val_acc: 0.0806 - val_top_5: 0.1894 - val_top_100: 0.4813\n",
      "Epoch 16/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 6.0047 - acc: 0.0974 - top_5: 0.2238 - top_100: 0.5820 - val_loss: 6.7613 - val_acc: 0.0806 - val_top_5: 0.1880 - val_top_100: 0.4831\n",
      "Epoch 17/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.9822 - acc: 0.0987 - top_5: 0.2266 - top_100: 0.5857 - val_loss: 6.7725 - val_acc: 0.0821 - val_top_5: 0.1872 - val_top_100: 0.4830\n",
      "Epoch 18/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.9615 - acc: 0.0997 - top_5: 0.2288 - top_100: 0.5888 - val_loss: 6.7728 - val_acc: 0.0815 - val_top_5: 0.1867 - val_top_100: 0.4797\n",
      "Epoch 19/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.9418 - acc: 0.1009 - top_5: 0.2308 - top_100: 0.5921 - val_loss: 6.7835 - val_acc: 0.0829 - val_top_5: 0.1892 - val_top_100: 0.4827\n",
      "Epoch 20/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 5.9251 - acc: 0.1025 - top_5: 0.2327 - top_100: 0.5942 - val_loss: 6.7943 - val_acc: 0.0826 - val_top_5: 0.1891 - val_top_100: 0.4842\n",
      "Epoch 21/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.9083 - acc: 0.1033 - top_5: 0.2344 - top_100: 0.5968 - val_loss: 6.8170 - val_acc: 0.0806 - val_top_5: 0.1875 - val_top_100: 0.4766\n",
      "Epoch 22/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.8946 - acc: 0.1039 - top_5: 0.2359 - top_100: 0.5992 - val_loss: 6.8209 - val_acc: 0.0832 - val_top_5: 0.1863 - val_top_100: 0.4795\n",
      "Epoch 23/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.8811 - acc: 0.1052 - top_5: 0.2378 - top_100: 0.6008 - val_loss: 6.8399 - val_acc: 0.0833 - val_top_5: 0.1870 - val_top_100: 0.4758\n",
      "Epoch 24/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.8680 - acc: 0.1065 - top_5: 0.2395 - top_100: 0.6025 - val_loss: 6.8416 - val_acc: 0.0840 - val_top_5: 0.1871 - val_top_100: 0.4768\n",
      "Epoch 25/100\n",
      "7735/7735 [==============================] - 45s 6ms/step - loss: 5.8569 - acc: 0.1070 - top_5: 0.2406 - top_100: 0.6043 - val_loss: 6.8489 - val_acc: 0.0834 - val_top_5: 0.1866 - val_top_100: 0.4792\n",
      "Epoch 26/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 5.8453 - acc: 0.1076 - top_5: 0.2420 - top_100: 0.6060 - val_loss: 6.8585 - val_acc: 0.0828 - val_top_5: 0.1853 - val_top_100: 0.4761\n",
      "Epoch 27/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.8356 - acc: 0.1083 - top_5: 0.2429 - top_100: 0.6081 - val_loss: 6.8670 - val_acc: 0.0855 - val_top_5: 0.1855 - val_top_100: 0.4759\n",
      "Epoch 28/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.8272 - acc: 0.1093 - top_5: 0.2439 - top_100: 0.6092 - val_loss: 6.8739 - val_acc: 0.0863 - val_top_5: 0.1851 - val_top_100: 0.4754\n",
      "Epoch 29/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.8163 - acc: 0.1096 - top_5: 0.2453 - top_100: 0.6104 - val_loss: 6.8691 - val_acc: 0.0868 - val_top_5: 0.1865 - val_top_100: 0.4749\n",
      "Epoch 30/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 5.8085 - acc: 0.1105 - top_5: 0.2462 - top_100: 0.6116 - val_loss: 6.8799 - val_acc: 0.0828 - val_top_5: 0.1860 - val_top_100: 0.4749\n",
      "Epoch 31/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 5.8008 - acc: 0.1110 - top_5: 0.2479 - top_100: 0.6129 - val_loss: 6.8913 - val_acc: 0.0841 - val_top_5: 0.1851 - val_top_100: 0.4747\n",
      "Epoch 32/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.7933 - acc: 0.1116 - top_5: 0.2484 - top_100: 0.6136 - val_loss: 6.8987 - val_acc: 0.0832 - val_top_5: 0.1856 - val_top_100: 0.4739\n",
      "Epoch 33/100\n",
      "7735/7735 [==============================] - 43s 6ms/step - loss: 5.7867 - acc: 0.1121 - top_5: 0.2489 - top_100: 0.6144 - val_loss: 6.8954 - val_acc: 0.0840 - val_top_5: 0.1849 - val_top_100: 0.4744\n",
      "Epoch 34/100\n",
      "7735/7735 [==============================] - 44s 6ms/step - loss: 5.7799 - acc: 0.1128 - top_5: 0.2499 - top_100: 0.6154 - val_loss: 6.9032 - val_acc: 0.0849 - val_top_5: 0.1852 - val_top_100: 0.4748\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  model = create_model(6, number_items)\n",
    "  adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "  model.compile(\n",
    "      optimizer=adam_optimizer,\n",
    "      loss=loss,\n",
    "      metrics= [\"acc\",top_5,top_100],\n",
    "      steps_per_execution=64\n",
    "  )\n",
    "model.fit(X_training,y_training,epochs=100, batch_size=128, validation_split = 0.01, verbose=1,\n",
    "          callbacks  = [EarlyStopping(monitor='val_acc', patience=5),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_acc', save_best_only=True)]\n",
    "            )\n",
    "model.save_weights('/tmp/best.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLAc8ZGmyvtw"
   },
   "source": [
    "# Obtaining Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNw-9X067qa2",
    "outputId": "688f442c-e73c-4ce2-f0e6-686e27f8c481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 5, 10)             236920    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100)               33600     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 23692)             2392892   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,663,412\n",
      "Trainable params: 2,663,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('best_model.h5', compile=False)\n",
    "\n",
    "#let's define a sparse categorical crossentropy to start!\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "\n",
    "# summarize model.\n",
    "model.summary()\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "      optimizer=adam_optimizer,\n",
    "      loss=loss,\n",
    "      metrics= [\"acc\",top_5,top_100],\n",
    "      steps_per_execution=32\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "dKjDJD_ez3fg"
   },
   "outputs": [],
   "source": [
    "leaderboard = pd.read_csv(\"test_leaderboard_sessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "VravqdCIEBrN"
   },
   "outputs": [],
   "source": [
    "def sessions_list_testing(sessions):\n",
    "    antique_session = sessions.iat[0,0]\n",
    "    list_sessions = []\n",
    "    actual_session = []\n",
    "    for i in tqdm(range(len(sessions))):\n",
    "        new_session = sessions.iat[i,0]\n",
    "        item = sessions.iat[i,1]\n",
    "        if(new_session != antique_session):\n",
    "            list_sessions.append(actual_session)\n",
    "            actual_session = []\n",
    "            antique_session = new_session\n",
    "        actual_session.append(item)\n",
    "    list_sessions.append(actual_session)\n",
    "    return list_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkzqeIqyA_Yh",
    "outputId": "568c84f1-f630-414c-eeef-270328ea52cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229354/229354 [00:11<00:00, 19712.23it/s]\n"
     ]
    }
   ],
   "source": [
    "session_item_testing = sessions_list_testing(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fI9tWmKRBQSe",
    "outputId": "448c41d0-7f2e-4fee-b109-eedcba0cc53d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:00, 268721.98it/s]\n"
     ]
    }
   ],
   "source": [
    "def testing_sequences(session_item2):\n",
    "    train_sequence = np.zeros((len(session_item2),5))\n",
    "    trobat = False\n",
    "    for i,x in tqdm(enumerate(session_item2)):\n",
    "        length = len(x)\n",
    "        llista = x.copy()\n",
    "        if(length < 5):\n",
    "            for j in range(5-length):\n",
    "                llista.insert(0,0)\n",
    "        if(length > 5):\n",
    "            for j in range(length-5):\n",
    "                llista.pop(0)\n",
    "        train_sequence[i][0] = llista[0]\n",
    "        train_sequence[i][1] = llista[1]\n",
    "        train_sequence[i][2] = llista[2]\n",
    "        train_sequence[i][3] = llista[3]\n",
    "        train_sequence[i][4] = llista[4]\n",
    "    return train_sequence\n",
    "\n",
    "sequence_testing = testing_sequences(session_item_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "UlItwp2ZBgyj"
   },
   "outputs": [],
   "source": [
    "X_testing = np.array(sequence_testing)\n",
    "X_testing = X_testing.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ls5xb1CB3aRv"
   },
   "outputs": [],
   "source": [
    "def testing_dataset(X2):\n",
    "    #first X.\n",
    "    X_test = np.zeros((X2.shape[0],X2.shape[1]))    \n",
    "    for i in range(X2.shape[0]):\n",
    "        for j in range(X2.shape[1]):\n",
    "            X_test[i,j] = item_index[X2[i,j]]\n",
    "\n",
    "    return X_test\n",
    "X_leaderboard = testing_dataset(X_testing)  \n",
    "X_leaderboard = X_leaderboard.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qjrb0vVNPwm"
   },
   "source": [
    "**Creating The prediction Fully with LSTM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "cBLxI5vtNPIf"
   },
   "outputs": [],
   "source": [
    "def generate_solution(X_test,leaderboard2, split = 100):\n",
    "    solution = [[]]\n",
    "    sessions_unique = leaderboard.session_id.unique()\n",
    "    for i in tqdm(range(int(50000/split))):\n",
    "      prediction = model.predict(X_test[split*i:split*(i+1)])\n",
    "      for j in range(split):\n",
    "        prediction_actual = prediction[j]\n",
    "        indexes = np.argpartition(prediction_actual, -100)[-100:]\n",
    "        best_100 = indexes[np.argsort(-prediction_actual[indexes])]\n",
    "        for k in range(100):\n",
    "          solution.append([int(sessions_unique[j+i*split]),index_item[int(best_100[k])],k+1])\n",
    "\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "md4bIfZcPN9x",
    "outputId": "f4a9c5ec-6989-4bc3-fd1c-834d097462b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:27<00:00,  5.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_solutions = generate_solution(X_leaderboard,leaderboard)\n",
    "final_solutions.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "hNJ0BCGrjLVq"
   },
   "outputs": [],
   "source": [
    "solutions = pd.DataFrame(final_solutions, columns = ['session_id','item_id', 'rank']).reset_index(drop = True)\n",
    "solutions_csv = solutions.to_csv\n",
    "solutions.to_csv(r'Simple_LSTM_Solution.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "rEhAOg5sj6bz",
    "outputId": "2d2138f3-ff53-4e4a-bb5d-d56bc48b7054"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c9601c7e-bd46-4c94-9d92-50bb873e9fbc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>16194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>1107</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>2672</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>21035</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>27630</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>26538</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>20397</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>20889</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>320</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>27416</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9601c7e-bd46-4c94-9d92-50bb873e9fbc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c9601c7e-bd46-4c94-9d92-50bb873e9fbc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c9601c7e-bd46-4c94-9d92-50bb873e9fbc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   session_id  item_id  rank\n",
       "0          26    16194     1\n",
       "1          26     1107     2\n",
       "2          26     2672     3\n",
       "3          26    21035     4\n",
       "4          26    27630     5\n",
       "5          26    26538     6\n",
       "6          26    20397     7\n",
       "7          26    20889     8\n",
       "8          26      320     9\n",
       "9          26    27416    10"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqH1lTp0zVVp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_1_Entrendada.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
