{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lUWr8gKNQLt3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from numpy import array\n",
        "from keras.models import load_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import platform\n",
        "import time\n",
        "import pathlib\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read all the data:\n",
        "items = pd.read_csv(\"item_features.csv\")\n",
        "purchase =  pd.read_csv(\"train_purchases.csv\")\n",
        "sessions =  pd.read_csv(\"train_sessions.csv\")"
      ],
      "metadata": {
        "id": "MUJRpzkMQMNq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "purchase['date'] = pd.to_datetime(purchase['date'])\n",
        "sessions['date'] = pd.to_datetime(sessions['date'])\n",
        "max_day = purchase['date'].max() #max date 31/05/2021 \n",
        "min_day = max_day -datetime.timedelta(31)\n",
        "cond = purchase['date'] >= min_day\n",
        "new_purchases = purchase[cond]\n",
        "top_seller = new_purchases['item_id'].value_counts()[0:100].index.to_list()"
      ],
      "metadata": {
        "id": "_Z-5Yes-QOgv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_day = sessions['date'].max() #max date 31/05/2021 \n",
        "testing_date = max_day -datetime.timedelta(31)\n",
        "cond_test = sessions['date'] >= testing_date\n",
        "cond_train = sessions['date'] < testing_date\n",
        "cond_test_purchase = purchase.date >= testing_date\n",
        "cond_train_purchase = purchase.date < testing_date\n",
        "sessions_train = sessions[cond_train]\n",
        "sessions_test = sessions[cond_test]\n",
        "purchase_train = purchase[cond_train_purchase]\n",
        "purchase_test = purchase[cond_test_purchase]"
      ],
      "metadata": {
        "id": "ZbaEJpPMQgvq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sessions_list(sessions,purchase):\n",
        "    antique_session = sessions.iat[0,0]\n",
        "    list_sessions = []\n",
        "    actual_session = []\n",
        "    purchase_session = 0\n",
        "    for i in tqdm(range(len(sessions))):\n",
        "        new_session = sessions.iat[i,0]\n",
        "        item = sessions.iat[i,1]\n",
        "        if(new_session != antique_session):\n",
        "            actual_session.append(purchase.iat[purchase_session,1])\n",
        "            purchase_session += 1\n",
        "            list_sessions.append(actual_session)\n",
        "            actual_session = []\n",
        "            antique_session = new_session\n",
        "        actual_session.append(item)\n",
        "    list_sessions.append(actual_session)\n",
        "    return list_sessions"
      ],
      "metadata": {
        "id": "4yn-tIE4QjQk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_item = sessions_list(sessions,purchase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huvCSDNFQk_L",
        "outputId": "24164a74-d3bc-4769-dd95-bfe1707a3acc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4743820/4743820 [03:35<00:00, 22045.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_sequences(session_item2):\n",
        "    train_sequence = np.zeros((len(session_item),6))\n",
        "    trobat = False\n",
        "    for i,x in tqdm(enumerate(session_item2)):\n",
        "        length = len(x)\n",
        "        llista = x.copy()\n",
        "        if(length-1 < 5):\n",
        "            for j in range(5-length+1):\n",
        "                llista.insert(0,0)\n",
        "        if(length-1 > 5):\n",
        "            for j in range(length-6):\n",
        "                llista.pop(0)\n",
        "        llista.pop(-1)                                    \n",
        "        train_sequence[i][0] = llista[0]\n",
        "        train_sequence[i][1] = llista[1]\n",
        "        train_sequence[i][2] = llista[2]\n",
        "        train_sequence[i][3] = llista[3]\n",
        "        train_sequence[i][4] = llista[4]\n",
        "        train_sequence[i][5] = x[len(x)-1]\n",
        "    return train_sequence\n",
        "\n",
        "sequence_training = training_sequences(session_item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg1LxXAiQl92",
        "outputId": "475c3a67-3b3f-4b8f-f123-1803ff9c7e33"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000000it [00:03, 304007.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(sequence_training)[:,:5] #sequence to predict from\n",
        "y = np.array(sequence_training)[:,5:] #next item in the sequence\n",
        "X = X.astype(int)\n",
        "y = y.astype(int)\n",
        "training = np.array(sequence_training)"
      ],
      "metadata": {
        "id": "7xlbltcCQppz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM:"
      ],
      "metadata": {
        "id": "bz-kLc56QzyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku"
      ],
      "metadata": {
        "id": "zJniifs2Qsoy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_items = len(items.item_id.unique())\n",
        "number_items += 1\n",
        "number_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQcv2QizQxm-",
        "outputId": "7cdf39ca-9d6d-42bc-a018-8f40737fa01a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23692"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_index = {}\n",
        "index_item = {}\n",
        "item_index[0] = 0\n",
        "index_item[0] = 0\n",
        "for i,x in enumerate(items.item_id.unique()):\n",
        "    index_item[i+1] = x\n",
        "    item_index[x] = i+1"
      ],
      "metadata": {
        "id": "L7bxZNRLQyuO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_dataset(X2,y2):\n",
        "    #first X.\n",
        "    X_training = np.zeros((X2.shape[0],X2.shape[1]))\n",
        "    y_training = np.zeros(y2.shape[0])\n",
        "    \n",
        "    for i in range(X2.shape[0]):\n",
        "        for j in range(X2.shape[1]):\n",
        "            X_training[i,j] = item_index[X2[i,j]]\n",
        "    \n",
        "    for i in range(y2.shape[0]):\n",
        "        y_training[i] = item_index[y2[i][0]]\n",
        "            \n",
        "    return X_training, y_training\n",
        "X_training, y_training = training_dataset(X,y)  \n",
        "X_training = X_training.astype(int)\n",
        "y_training = y_training.astype(int)"
      ],
      "metadata": {
        "id": "0HTXjD8cQ37R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "    \n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "i32c-lTKQ5lS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(6, number_items)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wE7JYBlQ68t",
        "outputId": "ed42bd1c-8706-459c-c698-851c21ad39bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 5, 10)             236920    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               44400     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 23692)             2392892   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,674,212\n",
            "Trainable params: 2,674,212\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's define a sparse categorical crossentropy to start!\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
        "      y_true=labels,\n",
        "      y_pred=logits,\n",
        "      from_logits=True\n",
        "    )"
      ],
      "metadata": {
        "id": "vSaLv2iQQ8EZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's define a sparse categorical crossentropy to start!\n",
        "def loss2(labels, logits):\n",
        "  print(labels)\n",
        "  labels = int(labels)\n",
        "  index = item_index[labels]\n",
        "  return 1\n",
        "  logits2 = np.array(logits)\n",
        "  return 1\n",
        "  res = list(sorted(enumerate(test_list)))[-100:]\n",
        "  for i in range(100):\n",
        "    if(index == res[i][0]): return 1\n",
        "  return 1"
      ],
      "metadata": {
        "id": "BOEfirzPwiIf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics**"
      ],
      "metadata": {
        "id": "kunRhnE9-p98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's define a sparse categorical crossentropy to start!\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "def top_5(y_true, y_pred):\n",
        "    return  tf.keras.metrics.sparse_top_k_categorical_accuracy(\n",
        "    y_true, y_pred, k=5\n",
        ")\n",
        "def top_50(y_true, y_pred):\n",
        "    return  tf.keras.metrics.sparse_top_k_categorical_accuracy(\n",
        "    y_true, y_pred, k=50\n",
        ")\n",
        "def top_100(y_true, y_pred):\n",
        "    return  tf.keras.metrics.sparse_top_k_categorical_accuracy(\n",
        "    y_true, y_pred, k=100\n",
        ")"
      ],
      "metadata": {
        "id": "SnfBlhr8-rJ3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Compilation**"
      ],
      "metadata": {
        "id": "mUSVKOVq-1rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss=loss,\n",
        "    metrics= [\"acc\",top_5,top_100]\n",
        ")"
      ],
      "metadata": {
        "id": "8kE0LVrtRc9q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_training,y_training,epochs=100, validation_split = 0.01, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-bUUBRSkwT_i",
        "outputId": "13bea123-f60e-4fc9-a68b-700b23380df7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30938/30938 [==============================] - 238s 8ms/step - loss: 8.2937 - acc: 0.0183 - top_5: 0.0500 - top_100: 0.2200 - val_loss: 7.5708 - val_acc: 0.0376 - val_top_5: 0.0970 - val_top_100: 0.3306\n",
            "Epoch 2/100\n",
            "30938/30938 [==============================] - 235s 8ms/step - loss: 7.3759 - acc: 0.0441 - top_5: 0.1141 - top_100: 0.3701 - val_loss: 7.1159 - val_acc: 0.0596 - val_top_5: 0.1463 - val_top_100: 0.4173\n",
            "Epoch 3/100\n",
            "30938/30938 [==============================] - 234s 8ms/step - loss: 7.0335 - acc: 0.0599 - top_5: 0.1469 - top_100: 0.4331 - val_loss: 6.9248 - val_acc: 0.0700 - val_top_5: 0.1660 - val_top_100: 0.4514\n",
            "Epoch 4/100\n",
            "30938/30938 [==============================] - 234s 8ms/step - loss: 6.8478 - acc: 0.0675 - top_5: 0.1635 - top_100: 0.4637 - val_loss: 6.8421 - val_acc: 0.0732 - val_top_5: 0.1709 - val_top_100: 0.4644\n",
            "Epoch 5/100\n",
            "30938/30938 [==============================] - 234s 8ms/step - loss: 6.7299 - acc: 0.0734 - top_5: 0.1735 - top_100: 0.4813 - val_loss: 6.7990 - val_acc: 0.0754 - val_top_5: 0.1752 - val_top_100: 0.4759\n",
            "Epoch 6/100\n",
            "30938/30938 [==============================] - 234s 8ms/step - loss: 6.6534 - acc: 0.0769 - top_5: 0.1805 - top_100: 0.4916 - val_loss: 6.7550 - val_acc: 0.0784 - val_top_5: 0.1802 - val_top_100: 0.4764\n",
            "Epoch 7/100\n",
            "30938/30938 [==============================] - 233s 8ms/step - loss: 6.6016 - acc: 0.0797 - top_5: 0.1853 - top_100: 0.4997 - val_loss: 6.7559 - val_acc: 0.0780 - val_top_5: 0.1815 - val_top_100: 0.4834\n",
            "Epoch 8/100\n",
            "30938/30938 [==============================] - 236s 8ms/step - loss: 6.5571 - acc: 0.0818 - top_5: 0.1896 - top_100: 0.5060 - val_loss: 6.7417 - val_acc: 0.0804 - val_top_5: 0.1866 - val_top_100: 0.4873\n",
            "Epoch 9/100\n",
            "30938/30938 [==============================] - 236s 8ms/step - loss: 6.5261 - acc: 0.0834 - top_5: 0.1925 - top_100: 0.5104 - val_loss: 6.7304 - val_acc: 0.0818 - val_top_5: 0.1895 - val_top_100: 0.4865\n",
            "Epoch 10/100\n",
            "30938/30938 [==============================] - 238s 8ms/step - loss: 6.4992 - acc: 0.0846 - top_5: 0.1947 - top_100: 0.5149 - val_loss: 6.7279 - val_acc: 0.0796 - val_top_5: 0.1905 - val_top_100: 0.4861\n",
            "Epoch 11/100\n",
            "30938/30938 [==============================] - 237s 8ms/step - loss: 6.4745 - acc: 0.0862 - top_5: 0.1973 - top_100: 0.5181 - val_loss: 6.7392 - val_acc: 0.0829 - val_top_5: 0.1892 - val_top_100: 0.4865\n",
            "Epoch 12/100\n",
            "30938/30938 [==============================] - 237s 8ms/step - loss: 6.4506 - acc: 0.0870 - top_5: 0.1990 - top_100: 0.5219 - val_loss: 6.7306 - val_acc: 0.0844 - val_top_5: 0.1915 - val_top_100: 0.4854\n",
            "Epoch 13/100\n",
            "30938/30938 [==============================] - 232s 8ms/step - loss: 6.4312 - acc: 0.0878 - top_5: 0.2011 - top_100: 0.5248 - val_loss: 6.7227 - val_acc: 0.0856 - val_top_5: 0.1900 - val_top_100: 0.4898\n",
            "Epoch 14/100\n",
            "30938/30938 [==============================] - 232s 7ms/step - loss: 6.4119 - acc: 0.0887 - top_5: 0.2030 - top_100: 0.5273 - val_loss: 6.7222 - val_acc: 0.0868 - val_top_5: 0.1887 - val_top_100: 0.4941\n",
            "Epoch 15/100\n",
            "30938/30938 [==============================] - 232s 7ms/step - loss: 6.3967 - acc: 0.0897 - top_5: 0.2041 - top_100: 0.5293 - val_loss: 6.7272 - val_acc: 0.0861 - val_top_5: 0.1949 - val_top_100: 0.4917\n",
            "Epoch 16/100\n",
            "30938/30938 [==============================] - 230s 7ms/step - loss: 6.3833 - acc: 0.0905 - top_5: 0.2058 - top_100: 0.5317 - val_loss: 6.7369 - val_acc: 0.0850 - val_top_5: 0.1912 - val_top_100: 0.4896\n",
            "Epoch 17/100\n",
            "30938/30938 [==============================] - 230s 7ms/step - loss: 6.3715 - acc: 0.0910 - top_5: 0.2071 - top_100: 0.5338 - val_loss: 6.7347 - val_acc: 0.0866 - val_top_5: 0.1923 - val_top_100: 0.4901\n",
            "Epoch 18/100\n",
            "30938/30938 [==============================] - 231s 7ms/step - loss: 6.3594 - acc: 0.0915 - top_5: 0.2078 - top_100: 0.5355 - val_loss: 6.7430 - val_acc: 0.0862 - val_top_5: 0.1935 - val_top_100: 0.4885\n",
            "Epoch 19/100\n",
            "17933/30938 [================>.............] - ETA: 1:36 - loss: 6.3030 - acc: 0.0936 - top_5: 0.2122 - top_100: 0.5433"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b356a40e7b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VravqdCIEBrN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}